{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Detection\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "The goal of this project is to build an image classification model that can accurately identify different types of animals from input images. We'll be using the animals detection images dataset, which contains over 3,000 labeled images of 5 different animal classes: cats, dogs, elephants, horses, and humans.\n",
    "\n",
    "Our final deliverable will be a Flask-based web application that allows users to upload an image and get a prediction of the most likely animal class that the image contains.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Steps\n",
    "\n",
    "1. Data exploration and preprocessing: We'll start by exploring the dataset and performing some basic preprocessing steps. This will include visualizing the images, checking for class balance, and splitting the dataset into training, validation, and test sets.\n",
    "\n",
    "2. Feature extraction and model selection: Next, we'll use transfer learning to extract features from the pre-trained VGG-16 model, which has been shown to be effective for image classification tasks. We'll also experiment with other pre-trained models such as ResNet, Inception, and EfficientNet, and select the one that performs the best on our validation set.\n",
    "\n",
    "3. Model training and evaluation: We'll then train the selected model on our training set and evaluate its performance on our validation set. We'll use techniques such as data augmentation, regularization, and hyperparameter tuning to improve the model's accuracy and prevent overfitting.\n",
    "\n",
    "4. Model deployment and Flask integration: Once we have a trained and validated model, we'll deploy it as a REST API using Flask. We'll create a simple web interface that allows users to upload an image and get a prediction of the most likely animal class that the image contains. We'll also implement error handling and user feedback to make the interface more user-friendly.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Implementation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to dataset and subdirectories\n",
    "base_path = \"/path/to/animals_detection_images\"\n",
    "train_path = os.path.join(base_path, \"train\")\n",
    "val_path = os.path.join(base_path, \"val\")\n",
    "test_path = os.path.join(base_path, \"test\")\n",
    "\n",
    "# Define batch size and image size\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Create image data generators with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators for training, validation, and test sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Plot some example images\n",
    "def plot_examples(generator, n_examples=6):\n",
    "    classes = list(generator.class_indices.keys())\n",
    "    for example in range(n_examples):\n",
    "        x, y = generator.next()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "    for i in range(batch_size):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.title(classes[np.argmax(y[i])])\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_examples(train_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define pre-trained model and its input shape\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=img_size+(3,))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define callbacks for model saving and early stopping\n",
    "checkpoint = ModelCheckpoint(\"animals_detection_model.h5\", save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train model on training set and validate on validation set\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate model on test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment and Flask Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from flask import Flask, jsonify, request\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Define paths to model and label files\n",
    "model_path = \"animals_detection_model.h5\"\n",
    "label_path = \"labels.txt\"\n",
    "\n",
    "# Load model and labels\n",
    "model = load_model(model_path)\n",
    "with open(label_path, \"r\") as f:\n",
    "    labels = [line strip() for line in f]\n",
    "\n",
    "# Define Flask app\n",
    "app = Flask(name)\n",
    "\n",
    "# Define predict function\n",
    "def predict(image):\n",
    "    # Preprocess input image\n",
    "    image = image.convert(\"RGB\").resize(img_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Get model prediction\n",
    "prediction = model.predict(image)[0]\n",
    "label = labels[np.argmax(prediction)]\n",
    "confidence = float(prediction[np.argmax(prediction)])\n",
    "\n",
    "return {\"label\": label, \"confidence\": confidence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Flask endpoints\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "return \"\"\"\n",
    "<h1>Animals Detection</h1>\n",
    "<form method=\"POST\" action=\"/predict\" enctype=\"multipart/form-data\">\n",
    "<input type=\"file\" name=\"file\"><br><br>\n",
    "<input type=\"submit\" value=\"Predict\">\n",
    "</form>\n",
    "\"\"\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict_endpoint():\n",
    "# Get input image from request\n",
    "file = request.files[\"file\"]\n",
    "image = Image.open(io.BytesIO(file.read()))\n",
    "\n",
    "# Get prediction\n",
    "prediction = predict(image)\n",
    "\n",
    "# Return prediction as JSON\n",
    "return jsonify(prediction)\n",
    "\n",
    "# Run Flask app\n",
    "if name == \"main\":\n",
    "app.run(debug=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code creates a Flask app and defines a `predict()` function that preprocesses an input image and returns a prediction. It then defines two Flask endpoints: `/` for a simple web interface that allows users to upload an image and get a prediction, and `/predict` for the API endpoint that calls the `predict()` function and returns the prediction as a JSON object. Finally, it runs the Flask app in debug mode.\n",
    "\n",
    "Note that we'll also need to create a `labels.txt` file that contains the animal class labels, one per line.\n",
    "\n",
    "With these steps, we have created a complete data science project that includes data preprocessing, model selection and training, and model deployment and integration with Flask. We can now run the Flask app, upload an image of an animal, and get a prediction of its most likely class.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
